# ğŸš€ Arquitetura Completa de MLOps na Oracle Cloud com Terraform e GitHub Actions

Este projeto implementa uma arquitetura completa de MLOps na Oracle Cloud Infrastructure (OCI), integrando as principais ferramentas do ecossistema de Machine Learning com automaÃ§Ã£o de infraestrutura e deploy.

![MLOps Architecture](docs/architecture-diagram.png)

## ğŸ“Œ Tecnologias Utilizadas

| Tecnologia | DescriÃ§Ã£o |
|------------|-----------|
| **Terraform** | Provisionamento da infraestrutura como cÃ³digo (IaC) |
| **GitHub Actions** | Pipeline de CI/CD para deploy automatizado |
| **MLflow** | Rastreamento de experimentos e modelos |
| **Airflow** | OrquestraÃ§Ã£o de pipelines de machine learning |
| **FastAPI** | Servidor REST para servir modelos |
| **Streamlit** | Interface interativa para visualizaÃ§Ã£o de resultados |
| **Flask** | Servidor REST para a API de prediÃ§Ã£o |
| **Docker** | ContainerizaÃ§Ã£o da aplicaÃ§Ã£o de backend |
| **MySQL** | Armazenamento de metadados (MLflow e Airflow) |
| **OCI Object Storage** | RepositÃ³rio de modelos e DAGs |
| **OCI Compute** | InstÃ¢ncias virtuais para serviÃ§os |
| **OCI VCN** | Rede virtual isolada |

## âš™ï¸ VisÃ£o Geral da Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Oracle Cloud Infrastructure                 â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                Virtual Cloud Network (VCN)                  â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚ â”‚
â”‚  â”‚  â”‚  Public Subnet   â”‚  â”‚  Private Subnet  â”‚               â”‚ â”‚
â”‚  â”‚  â”‚                  â”‚  â”‚                  â”‚               â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚               â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  MLflow    â”‚  â”‚  â”‚  â”‚   MySQL    â”‚ â”‚               â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Instance  â”‚â—„â”€â”¼â”€â”€â”¼â”€â”€â”‚  Database  â”‚ â”‚               â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚               â”‚ â”‚
â”‚  â”‚  â”‚        â–²         â”‚  â”‚                  â”‚               â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Airflow   â”‚  â”‚                                      â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Instance  â”‚â—„â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                               â”‚      â”‚ â”‚
â”‚  â”‚  â”‚        â–²         â”‚                               â”‚      â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                               â”‚      â”‚ â”‚
â”‚  â”‚  â”‚  â”‚FastAPI/UI  â”‚  â”‚                               â”‚      â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Instance  â”‚  â”‚                               â”‚      â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                               â”‚      â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                         â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚        â”‚
â”‚  â”‚           OCI Object Storage                     â”‚  â”‚        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚  â”‚        â”‚
â”‚  â”‚  â”‚ MLflow Bucket   â”‚  â”‚ Airflow Bucket  â”‚       â”‚â—„â”€â”˜        â”‚
â”‚  â”‚  â”‚  (Artifacts)    â”‚  â”‚     (DAGs)      â”‚       â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principais

| Componente | Tecnologia | FunÃ§Ã£o Principal | Recursos OCI |
|------------|------------|------------------|--------------|
| **Servidor de Tracking** | MLflow (Compute) | Registro e versionamento de experimentos | VM.Standard.E4.Flex (2 OCPUs, 16GB RAM) |
| **Orquestrador** | Airflow (Compute) | Agendamento e execuÃ§Ã£o das DAGs | VM.Standard.E4.Flex (2 OCPUs, 16GB RAM) |
| **API/Interface** | FastAPI + Streamlit (Compute) | DisponibilizaÃ§Ã£o dos modelos | VM.Standard.E4.Flex (2 OCPUs, 16GB RAM) |
| **Banco de Dados** | MySQL Database System | Metadados (MLflow e Airflow) | MySQL.VM.Standard.E4.1.8GB |
| **Armazenamento** | Object Storage | Artefatos MLflow e DAGs Airflow | 2 Buckets |
| **Rede** | VCN | Isolamento e seguranÃ§a | VCN com subnets pÃºblicas/privadas |

## ğŸ§© Componentes da Infraestrutura

### 1. **Virtual Cloud Network (VCN)**
- **Subnet PÃºblica**: Hosts para MLflow, Airflow e API com acesso Ã  internet
- **Subnet Privada**: MySQL Database isolado
- **Internet Gateway**: Acesso externo para subnet pÃºblica
- **NAT Gateway**: Acesso internet para subnet privada
- **Service Gateway**: Acesso a serviÃ§os OCI (Object Storage)
- **Security Lists**: Firewall para portas especÃ­ficas (22, 5000, 8080, 8000, 8501, 3306)

### 2. **Compute Instances**
Todas as instÃ¢ncias executam Oracle Linux 8 com scripts de inicializaÃ§Ã£o automatizados.

#### MLflow Instance
- **Shape**: VM.Standard.E4.Flex (2 OCPUs, 16GB RAM)
- **FunÃ§Ã£o**: Servidor de tracking MLflow
- **Porta**: 5000
- **ConfiguraÃ§Ã£o**: Conectado ao MySQL e Object Storage

#### Airflow Instance
- **Shape**: VM.Standard.E4.Flex (2 OCPUs, 16GB RAM)
- **FunÃ§Ã£o**: OrquestraÃ§Ã£o de pipelines
- **Porta**: 8080
- **ConfiguraÃ§Ã£o**: LocalExecutor, sync automÃ¡tico de DAGs do Object Storage

#### API Instance
- **Shape**: VM.Standard.E4.Flex (2 OCPUs, 16GB RAM)
- **FunÃ§Ã£o**: Servir modelos via FastAPI e interface Streamlit
- **Portas**: 8000 (FastAPI), 8501 (Streamlit)

### 3. **MySQL Database System**
- **Shape**: MySQL.VM.Standard.E4.1.8GB
- **Storage**: 50GB
- **Databases**: `mlflow` e `airflow`
- **Backup**: Habilitado (retenÃ§Ã£o de 7 dias)

### 4. **Object Storage**
- **MLflow Bucket**: Armazena modelos treinados e artefatos
- **Airflow Bucket**: ContÃ©m scripts de pipeline (DAGs)
- **Versionamento**: Habilitado em ambos

## ğŸ“‹ PrÃ©-requisitos

### OCI Account
1. Conta ativa na Oracle Cloud Infrastructure
2. Tenancy OCID
3. User OCID com permissÃµes adequadas
4. Compartment OCID onde os recursos serÃ£o criados

### Credenciais OCI
1. API Key gerada (chave privada e fingerprint)
2. Par de chaves SSH para acesso Ã s instÃ¢ncias

### Ferramentas Locais (para desenvolvimento)
```bash
# Terraform
terraform --version  # >= 1.6.0

# OCI CLI (opcional)
oci --version

# Git
git --version

# Docker
docker --version
```

## ğŸš€ Como Usar

### 1. Clonar o RepositÃ³rio

```bash
git clone https://github.com/Pabloserrapxx/Projeto_MLOps.git
cd Projeto_MLOps
```

### 2. Configurar GitHub Secrets

Acesse `Settings > Secrets and variables > Actions` no seu repositÃ³rio e adicione:

| Secret Name | DescriÃ§Ã£o | Como Obter |
|-------------|-----------|------------|
| `OCI_TENANCY_OCID` | OCID do Tenancy | Console OCI > Profile > Tenancy |
| `OCI_USER_OCID` | OCID do usuÃ¡rio | Console OCI > Profile > User Settings |
| `OCI_FINGERPRINT` | Fingerprint da API Key | Console OCI > API Keys |
| `OCI_PRIVATE_KEY` | Chave privada PEM (conteÃºdo completo) | Arquivo `.pem` gerado |
| `OCI_REGION` | RegiÃ£o (ex: us-ashburn-1) | Escolha da regiÃ£o |
| `OCI_COMPARTMENT_ID` | OCID do compartment | Console OCI > Identity > Compartments |
| `SSH_PUBLIC_KEY` | Chave pÃºblica SSH | `cat ~/.ssh/id_rsa.pub` |
| `DB_ADMIN_PASSWORD` | Senha do MySQL (mÃ­n. 8 caracteres) | Definir senha segura |

### 3. Deploy via GitHub Actions

#### Deploy AutomÃ¡tico (Push to Main)
```bash
git add .
git commit -m "Deploy MLOps infrastructure"
git push origin main
```

O GitHub Actions irÃ¡ automaticamente:
- Validar cÃ³digo Terraform
- Executar `terraform plan`
- Aplicar `terraform apply` (se push na branch main)

#### Deploy Manual

1. Acesse a aba `Actions` no GitHub
2. Selecione o workflow `Deploy MLOps Infrastructure to OCI`
3. Clique em `Run workflow`
4. Escolha a aÃ§Ã£o: `plan`, `apply`, ou `destroy`

### 4. Deploy Local (Alternativo)

```bash
# Navegar para o diretÃ³rio terraform
cd terraform

# Criar arquivo terraform.tfvars
cat > terraform.tfvars <<EOF
tenancy_ocid       = "ocid1.tenancy.oc1..xxx"
user_ocid          = "ocid1.user.oc1..xxx"
fingerprint        = "xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx:xx"
private_key_path   = "~/.oci/oci_api_key.pem"
region             = "us-ashburn-1"
compartment_id     = "ocid1.compartment.oc1..xxx"
ssh_public_key     = "ssh-rsa AAAAB3NzaC1yc2E..."
db_admin_password  = "SuaSenhaSegura123!"
EOF

# Inicializar Terraform
terraform init

# Validar configuraÃ§Ã£o
terraform validate

# Planejar infraestrutura
terraform plan

# Aplicar (criar recursos)
terraform apply

# Destruir (remover todos os recursos)
terraform destroy
```

## ğŸ“Š Acessando os ServiÃ§os

ApÃ³s o deploy (aguarde 5-10 minutos para inicializaÃ§Ã£o completa):

### MLflow Tracking Server
```
http://<mlflow_public_ip>:5000
```
- Visualizar experimentos
- Comparar mÃ©tricas
- Registrar modelos

### Airflow Web UI
```
http://<airflow_public_ip>:8080
```
- **Username**: `admin`
- **Password**: `admin`
- Gerenciar DAGs
- Monitorar execuÃ§Ãµes

### FastAPI Documentation
```
http://<api_public_ip>:8000/docs
```
- Testar endpoints
- Ver especificaÃ§Ã£o OpenAPI
- Fazer prediÃ§Ãµes

### Streamlit Dashboard
```
http://<api_public_ip>:8501
```
- Interface visual
- Fazer prediÃ§Ãµes interativas
- Visualizar mÃ©tricas

### Frontend e Backend (Local)

Para rodar o frontend e o backend localmente:

**Backend:**
```bash
cd backend
docker build -t iris-prediction-api .
docker run -p 5000:5000 iris-prediction-api
```
A API estarÃ¡ disponÃ­vel em `http://127.0.0.1:5000`.

**Frontend:**
Abra o arquivo `frontend/index.html` em seu navegador.

## ğŸ”„ Workflow CI/CD

### Jobs do GitHub Actions

1. **terraform-validation**: Valida formataÃ§Ã£o e sintaxe
2. **terraform-plan**: Gera plano de execuÃ§Ã£o (PRs)
3. **terraform-apply**: Aplica mudanÃ§as (branch main)
4. **terraform-destroy**: DestrÃ³i infraestrutura (manual)

## ğŸ“ Estrutura do Projeto

```
Projeto_MLOps/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml          # GitHub Actions workflow
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ provider.tf             # ConfiguraÃ§Ã£o do provider OCI
â”‚   â”œâ”€â”€ variables.tf            # VariÃ¡veis de entrada
â”‚   â”œâ”€â”€ outputs.tf              # Outputs da infraestrutura
â”‚   â”œâ”€â”€ network.tf              # VCN, subnets, gateways
â”‚   â”œâ”€â”€ compute.tf              # InstÃ¢ncias EC2
â”‚   â”œâ”€â”€ database.tf             # MySQL Database System
â”‚   â””â”€â”€ storage.tf              # Object Storage buckets
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ mlflow_init.sh          # Script de inicializaÃ§Ã£o MLflow
â”‚   â”œâ”€â”€ airflow_init.sh         # Script de inicializaÃ§Ã£o Airflow
â”‚   â””â”€â”€ api_init.sh             # Script de inicializaÃ§Ã£o API/Streamlit
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ example_dag.py          # Exemplo de DAG Airflow
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # Flask API
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ Dockerfile              # Dockerfile for backend
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # HTML file
â”‚   â”œâ”€â”€ style.css               # CSS file
â”‚   â””â”€â”€ script.js               # JavaScript file
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # AplicaÃ§Ã£o FastAPI (gerada na instÃ¢ncia)
â”‚   â””â”€â”€ streamlit_app.py        # Dashboard Streamlit (gerada na instÃ¢ncia)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md         # DocumentaÃ§Ã£o da arquitetura
â”‚   â”œâ”€â”€ setup-guide.md          # Guia de configuraÃ§Ã£o
â”‚   â””â”€â”€ troubleshooting.md      # ResoluÃ§Ã£o de problemas
â””â”€â”€ README.md                   # Este arquivo
```

## ğŸ› ï¸ Fluxo de Trabalho MLOps

### 1. Desenvolvimento do Modelo

```python
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier

# Configurar tracking
mlflow.set_tracking_uri("http://<mlflow_ip>:5000")
mlflow.set_experiment("my-experiment")

# Treinar modelo
with mlflow.start_run():
    model = RandomForestClassifier()
    model.fit(X_train, y_train)
    
    # Log metrics
    mlflow.log_metric("accuracy", accuracy)
    
    # Log model
    mlflow.sklearn.log_model(model, "model")
```

### 2. OrquestraÃ§Ã£o com Airflow

Crie uma DAG em `dags/training_pipeline.py`:

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def train_model():
    # CÃ³digo de treinamento
    pass

def evaluate_model():
    # CÃ³digo de avaliaÃ§Ã£o
    pass

dag = DAG(
    'ml_training_pipeline',
    start_date=datetime(2024, 1, 1),
    schedule_interval='@daily'
)

train = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag
)

evaluate = PythonOperator(
    task_id='evaluate_model',
    python_callable=evaluate_model,
    dag=dag
)

train >> evaluate
```

Upload para OCI:
```bash
oci os object put --bucket-name airflow-dags --file dags/training_pipeline.py
```

### 3. Deploy do Modelo

```python
# Registrar modelo no MLflow
mlflow.register_model("runs:/<run_id>/model", "MyModel")

# Promover para produÃ§Ã£o
client = mlflow.tracking.MlflowClient()
client.transition_model_version_stage(
    name="MyModel",
    version=1,
    stage="Production"
)
```

### 4. Servir Modelo via API

```python
import requests

# Fazer prediÃ§Ã£o
response = requests.post(
    "http://<api_ip>:8000/predict/MyModel/Production",
    json={"data": [[5.1, 3.5, 1.4, 0.2]]}
)

print(response.json())
# {"predictions": [0], "model_name": "MyModel", "model_version": "Production"}
```

## ğŸ”’ SeguranÃ§a

### Network Security
- Subnet privada para banco de dados
- Security Lists restritivas
- NAT Gateway para acesso controlado Ã  internet

### Credentials Management
- Senhas armazenadas em GitHub Secrets
- Chaves SSH para acesso Ã s instÃ¢ncias
- API Keys OCI com least privilege

### Best Practices
- Atualize regularmente as dependÃªncias
- Use senhas fortes para o MySQL
- Restrinja acesso SSH por IP quando possÃ­vel
- Habilite MFA na conta OCI

## ğŸ’° Estimativa de Custos

Custos mensais estimados (regiÃ£o us-ashburn-1):

| Recurso | Quantidade | Custo Estimado |
|---------|------------|----------------|
| Compute VM.Standard.E4.Flex (2 OCPUs) | 3x | ~$88/mÃªs |
| MySQL Database System | 1x | ~$90/mÃªs |
| Object Storage (50GB) | 2x buckets | ~/mÃªs |
| VCN, Gateways | 1x | GrÃ¡tis* |
| **Total Estimado** | | **~79/mÃªs** |

*Alguns recursos de rede sÃ£o gratuitos no Free Tier

### Reduzir Custos
- Use Free Tier: 2x VM.Standard.E2.1.Micro Always Free
- Reduza OCPUs para 1 quando possÃ­vel
- Use Autonomous Database Free Tier
- Agende desligamento de instÃ¢ncias em horÃ¡rios ociosos

## ğŸ› Troubleshooting

### ServiÃ§os nÃ£o iniciam apÃ³s deploy

**Problema**: Services nÃ£o respondem nos endpoints.

**SoluÃ§Ã£o**:
```bash
# SSH na instÃ¢ncia
ssh -i ~/.ssh/id_rsa opc@<instance_ip>

# Verificar status dos serviÃ§os
sudo systemctl status mlflow       # Para MLflow
sudo systemctl status airflow-webserver  # Para Airflow
sudo systemctl status fastapi      # Para FastAPI

# Ver logs
sudo journalctl -u mlflow -n 100
sudo journalctl -u airflow-webserver -n 100
```

### Erro de conexÃ£o com MySQL

**Problema**: MLflow/Airflow nÃ£o conectam ao banco.

**SoluÃ§Ã£o**:
```bash
# Testar conexÃ£o
mysql -h <db_endpoint> -u admin -p

# Verificar security list
# Certifique-se de que a porta 3306 estÃ¡ aberta entre subnets
```

### DAGs nÃ£o aparecem no Airflow

**Problema**: DAGs enviados ao bucket nÃ£o aparecem.

**SoluÃ§Ã£o**:
```bash
# Verificar sincronizaÃ§Ã£o
ssh opc@<airflow_ip>
/home/opc/sync_dags.sh

# Verificar timer
sudo systemctl status airflow-dag-sync.timer
```

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o
- [Oracle Cloud Infrastructure](https://docs.oracle.com/en-us/iaas/Content/home.htm)
- [Terraform OCI Provider](https://registry.terraform.io/providers/oracle/oci/latest/docs)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Apache Airflow](https://airflow.apache.org/docs/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://docs.streamlit.io/)

### PrÃ³ximos Passos
- [ ] Implementar monitoramento com OCI Monitoring
- [ ] Adicionar alertas com OCI Notifications
- [ ] Configurar Load Balancer para alta disponibilidade
- [ ] Implementar autoscaling de compute instances
- [ ] Adicionar testes automatizados
- [ ] Configurar backup automÃ¡tico de buckets
- [ ] Implementar CI/CD para modelos (MLOps Level 2)

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## âœ¨ Autores

- **Pablo Serra** - [@Pabloserrapxx](https://github.com/Pabloserrapxx)

## ğŸ™ Agradecimentos

- Comunidade MLflow
- Comunidade Apache Airflow
- Oracle Cloud Infrastructure
- HashiCorp Terraform

---

**âš ï¸ Nota**: Este Ã© um projeto educacional/demonstrativo. Para ambientes de produÃ§Ã£o, considere adicionar:
- HTTPS com certificados SSL
- AutenticaÃ§Ã£o robusta (OAuth2, LDAP)
- Backup e disaster recovery
- Monitoramento e observabilidade
- Alta disponibilidade e redundÃ¢ncia